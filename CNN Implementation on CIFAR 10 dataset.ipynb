{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Pavan Pyla\n### 22232 \n### MDSC - 302P\n### Implementing CNN on CIFAR 10 dataset","metadata":{}},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport pandas as pd\nimport torch.optim as optim\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:56.583108Z","iopub.execute_input":"2023-09-22T06:33:56.583580Z","iopub.status.idle":"2023-09-22T06:33:56.591770Z","shell.execute_reply.started":"2023-09-22T06:33:56.583537Z","shell.execute_reply":"2023-09-22T06:33:56.590457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:56.594574Z","iopub.execute_input":"2023-09-22T06:33:56.595020Z","iopub.status.idle":"2023-09-22T06:33:56.603621Z","shell.execute_reply.started":"2023-09-22T06:33:56.594986Z","shell.execute_reply":"2023-09-22T06:33:56.602684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device ","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:56.604768Z","iopub.execute_input":"2023-09-22T06:33:56.605087Z","iopub.status.idle":"2023-09-22T06:33:56.619103Z","shell.execute_reply.started":"2023-09-22T06:33:56.605063Z","shell.execute_reply":"2023-09-22T06:33:56.617936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 8\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:56.620370Z","iopub.execute_input":"2023-09-22T06:33:56.621085Z","iopub.status.idle":"2023-09-22T06:33:58.337401Z","shell.execute_reply.started":"2023-09-22T06:33:56.621050Z","shell.execute_reply":"2023-09-22T06:33:58.336268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:58.340774Z","iopub.execute_input":"2023-09-22T06:33:58.348667Z","iopub.status.idle":"2023-09-22T06:33:58.974199Z","shell.execute_reply.started":"2023-09-22T06:33:58.348613Z","shell.execute_reply":"2023-09-22T06:33:58.972931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the train and validation data sets ","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_size = len(trainset)                        # Getting the validation set from training data which is 10% of training data\nval_size = int(0.1 * train_size)\n\ntrain_dataset, val_dataset = random_split(trainset, [train_size - val_size, val_size])\n\nprint(f\"Training set size: {len(train_dataset)}\")\nprint(f\"Validation set size: {len(val_dataset)}\")\nprint(f\"Test set size: {len(testset)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:58.976514Z","iopub.execute_input":"2023-09-22T06:33:58.977141Z","iopub.status.idle":"2023-09-22T06:33:58.998954Z","shell.execute_reply.started":"2023-09-22T06:33:58.977099Z","shell.execute_reply":"2023-09-22T06:33:58.998018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNISTConvNet(nn.Module):\n    def __init__(self):\n        super(MNISTConvNet, self).__init__()\n        self.conv1 = nn.Sequential(\n          nn.Conv2d(3, 32, 5),\n          nn.ReLU(),\n          nn.MaxPool2d(2,2)\n        )\n        self.conv2 = nn.Sequential(\n          nn.Conv2d(32, 64, 5, padding='same'),\n          nn.ReLU(),\n          nn.MaxPool2d(2,2)\n        )\n        self.fc1 = nn.Sequential(\n          nn.Flatten(),\n          nn.Linear(7*7*64, 1024),\n          nn.Dropout(0.5),\n          nn.Linear(1024, 10)\n        )\n    def forward(self, X):\n        x = self.conv1(X)\n        x = self.conv2(x)\n        x = x.view(x.size(0), -1)  \n        return self.fc1(x)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.002919Z","iopub.execute_input":"2023-09-22T06:33:59.003510Z","iopub.status.idle":"2023-09-22T06:33:59.013335Z","shell.execute_reply.started":"2023-09-22T06:33:59.003476Z","shell.execute_reply":"2023-09-22T06:33:59.012382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.014884Z","iopub.execute_input":"2023-09-22T06:33:59.015549Z","iopub.status.idle":"2023-09-22T06:33:59.035773Z","shell.execute_reply.started":"2023-09-22T06:33:59.015499Z","shell.execute_reply":"2023-09-22T06:33:59.034551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_net =MNISTConvNet()  ","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.037550Z","iopub.execute_input":"2023-09-22T06:33:59.038347Z","iopub.status.idle":"2023-09-22T06:33:59.111347Z","shell.execute_reply.started":"2023-09-22T06:33:59.038314Z","shell.execute_reply":"2023-09-22T06:33:59.110312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_net.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.116092Z","iopub.execute_input":"2023-09-22T06:33:59.118489Z","iopub.status.idle":"2023-09-22T06:33:59.135902Z","shell.execute_reply.started":"2023-09-22T06:33:59.118451Z","shell.execute_reply":"2023-09-22T06:33:59.135019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  # Taking Cross Entropy Loss as the Loss function\noptimizer = optim.SGD(simple_net.parameters(), lr=0.01)  # optimizer is SGD stochastic gradient descent","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.140255Z","iopub.execute_input":"2023-09-22T06:33:59.142685Z","iopub.status.idle":"2023-09-22T06:33:59.150328Z","shell.execute_reply.started":"2023-09-22T06:33:59.142638Z","shell.execute_reply":"2023-09-22T06:33:59.149293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading all the datasets into dataloader\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)             # batch size is 64\ntest_loader = DataLoader(testset, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.155188Z","iopub.execute_input":"2023-09-22T06:33:59.158217Z","iopub.status.idle":"2023-09-22T06:33:59.169178Z","shell.execute_reply.started":"2023-09-22T06:33:59.158181Z","shell.execute_reply":"2023-09-22T06:33:59.168118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainval_loop(train_loader, val_loader, simple_net, criterion, optimizer):\n\n    simple_net.train()\n    correct_val = 0\n    total_val = 0\n    train_loss=0\n    size = len(train_loader.dataset)\n    for batch, (X, y) in enumerate(train_loader):\n        X = X.to(device)\n        y = y.to(device)\n\n        pred = simple_net(X)\n        loss = criterion(pred, y)\n\n                                                 # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        train_loss +=loss.item()\n        \n        if batch % 100 == 0:\n            current = batch * len(X)\n#             print(f\"Training loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\") #printing training loss\n    training_loss.append(train_loss/len(train_loader))\n    print(f\"Training loss: {train_loss/len(train_loader)}\") #printing training loss\n\n    simple_net.eval()\n\n    # Validation loop\n    val_loss = 0\n    val_size = len(val_loader.dataset)\n    with torch.no_grad():\n        for batch, (X, y) in enumerate(val_loader):\n            X = X.to(device)\n            y = y.to(device)\n            # Compute prediction and loss\n#             outputs = model(inputs)\n            pred = simple_net(X)\n            loss = criterion(pred, y)\n            val_loss += loss.item()\n            ## Accuracy calculation\n            \n            \n            _, predicted = torch.max(pred.data, 1)\n            total_val += y.size(0)\n            correct_val += (predicted == y).sum().item()\n            \n            if batch % 100 == 0:\n                current = batch * len(X)\n#                 print(f\"Validation loss: {loss.item():>7f}  [{current:>5d}/{val_size:>5d}]\") #printing validation loss\n    val_accuracy = 100 * correct_val / total_val\n    print(f\" Train Accuracy: {val_accuracy:.2f}%\")\n    avg_val_loss = val_loss / len(val_loader)\n    validation_loss.append(avg_val_loss)\n    \n    print(f\"Avg. Validation loss: {avg_val_loss:>7f}\")            #printing average validation loss\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.173896Z","iopub.execute_input":"2023-09-22T06:33:59.176627Z","iopub.status.idle":"2023-09-22T06:33:59.195585Z","shell.execute_reply.started":"2023-09-22T06:33:59.176594Z","shell.execute_reply":"2023-09-22T06:33:59.194567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss=[]\nvalidation_loss=[]\nepochs = 50\nfor t in range(epochs):\n    print(f'===EPOCH===  {t}')\n    trainval_loop(train_loader,val_loader, simple_net, criterion, optimizer)      # running train_val loop by 10 times","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:33:59.205934Z","iopub.execute_input":"2023-09-22T06:33:59.209116Z","iopub.status.idle":"2023-09-22T06:44:33.495038Z","shell.execute_reply.started":"2023-09-22T06:33:59.209076Z","shell.execute_reply":"2023-09-22T06:44:33.494031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the losses\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, epochs+1), training_loss, label='Training Loss')\nplt.plot(range(1, epochs+1), validation_loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:33.496769Z","iopub.execute_input":"2023-09-22T06:44:33.497203Z","iopub.status.idle":"2023-09-22T06:44:33.816773Z","shell.execute_reply.started":"2023-09-22T06:44:33.497167Z","shell.execute_reply":"2023-09-22T06:44:33.815837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_test=0\nloss=0\ncorrect_test=0\ntest_loss =0\nwith torch.no_grad():\n        for batch, (X, y) in enumerate(test_loader):\n            X = X.to(device)\n            y = y.to(device)\n            # Compute prediction and loss\n#             outputs = model(inputs)\n            pred = simple_net(X)\n            loss = criterion(pred, y)\n            test_loss += loss.item()\n            ## Accuracy calculation\n            \n            \n            _, predicted = torch.max(pred.data, 1)\n            total_test += y.size(0)\n            correct_test += (predicted == y).sum().item()\n            \n            if batch % 100 == 0:\n                current = batch * len(X)\n        test_accuracy = 100 * correct_test / total_test\n        print(f\" Test Accuracy: {test_accuracy:.2f}%\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:33.818107Z","iopub.execute_input":"2023-09-22T06:44:33.818913Z","iopub.status.idle":"2023-09-22T06:44:36.095212Z","shell.execute_reply.started":"2023-09-22T06:44:33.818878Z","shell.execute_reply":"2023-09-22T06:44:36.094221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.block1 = nn.Sequential(\n        nn.Conv2d(3, 32, 3, 1),\n        nn.BatchNorm2d(32),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(32, 64, 3, 1),\n        nn.BatchNorm2d(64),\n        nn.ReLU(inplace=True),\n        nn.MaxPool2d(2),\n        nn.Dropout(0.25),\n         )\n        self.block2 = nn.Sequential(\n         nn.Flatten(),\n         nn.Linear(12544, 128),\n         nn.BatchNorm1d(128),\n         nn.ReLU(inplace=True),\n         nn.Dropout(0.5),\n         nn.Linear(128,10),\n         nn.BatchNorm1d(10)\n         )\n    def forward(self, x):\n        x = self.block1(x)\n        return self.block2(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.096773Z","iopub.execute_input":"2023-09-22T06:44:36.097379Z","iopub.status.idle":"2023-09-22T06:44:36.106183Z","shell.execute_reply.started":"2023-09-22T06:44:36.097343Z","shell.execute_reply":"2023-09-22T06:44:36.105133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple =Net() ","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.107796Z","iopub.execute_input":"2023-09-22T06:44:36.108169Z","iopub.status.idle":"2023-09-22T06:44:36.130874Z","shell.execute_reply.started":"2023-09-22T06:44:36.108121Z","shell.execute_reply":"2023-09-22T06:44:36.130002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"simple.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.132301Z","iopub.execute_input":"2023-09-22T06:44:36.132646Z","iopub.status.idle":"2023-09-22T06:44:36.143005Z","shell.execute_reply.started":"2023-09-22T06:44:36.132615Z","shell.execute_reply":"2023-09-22T06:44:36.141777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  # Taking Cross Entropy Loss as the Loss function\noptimizer = optim.RMSprop(simple.parameters(), lr=0.0001)  # optimizer is SGD stochastic gradient descent","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.144766Z","iopub.execute_input":"2023-09-22T06:44:36.145165Z","iopub.status.idle":"2023-09-22T06:44:36.151317Z","shell.execute_reply.started":"2023-09-22T06:44:36.145132Z","shell.execute_reply":"2023-09-22T06:44:36.150025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading all the datasets into dataloader\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)             # batch size is 64\ntest_loader = DataLoader(testset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.153132Z","iopub.execute_input":"2023-09-22T06:44:36.153595Z","iopub.status.idle":"2023-09-22T06:44:36.162100Z","shell.execute_reply.started":"2023-09-22T06:44:36.153562Z","shell.execute_reply":"2023-09-22T06:44:36.161149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss=[]\nvalidation_loss=[]","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.163023Z","iopub.execute_input":"2023-09-22T06:44:36.163293Z","iopub.status.idle":"2023-09-22T06:44:36.172896Z","shell.execute_reply.started":"2023-09-22T06:44:36.163269Z","shell.execute_reply":"2023-09-22T06:44:36.171977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainval_loop(train_loader, val_loader, simple_net, criterion, optimizer):\n\n    simple.train()\n    correct_val = 0\n    total_val = 0\n    train_loss=0\n    size = len(train_loader.dataset)\n    for batch, (X, y) in enumerate(train_loader):\n        X = X.to(device)\n        y = y.to(device)\n\n        pred = simple(X)\n        loss = criterion(pred, y)\n\n                                                 # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        train_loss +=loss.item()\n\n        if batch % 100 == 0:\n            current = batch * len(X)\n#             print(f\"Training loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\") #printing training loss\n    training_loss.append(train_loss/len(train_loader))\n    print(f\"Training loss: {train_loss/len(train_loader)}\") #printing training loss\n\n    simple.eval()\n\n    # Validation loop\n    val_loss = 0\n    val_size = len(val_loader.dataset)\n    with torch.no_grad():\n        for batch, (X, y) in enumerate(val_loader):\n            X = X.to(device)\n            y = y.to(device)\n            # Compute prediction and loss\n#             outputs = model(inputs)\n            pred = simple(X)\n            loss = criterion(pred, y)\n            val_loss += loss.item()\n            ## Accuracy calculation\n\n\n            _, predicted = torch.max(pred.data, 1)\n            total_val += y.size(0)\n            correct_val += (predicted == y).sum().item()\n\n            if batch % 100 == 0:\n                current = batch * len(X)\n#                 print(f\"Validation loss: {loss.item():>7f}  [{current:>5d}/{val_size:>5d}]\") #printing validation loss\n    val_accuracy = 100 * correct_val / total_val\n    print(f\" Train Accuracy: {val_accuracy:.2f}%\")\n    avg_val_loss = val_loss / len(val_loader)\n    validation_loss.append(avg_val_loss)\n\n    print(f\"Avg. Validation loss: {avg_val_loss:>7f}\")            #printing average validation loss\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.174518Z","iopub.execute_input":"2023-09-22T06:44:36.174848Z","iopub.status.idle":"2023-09-22T06:44:36.188223Z","shell.execute_reply.started":"2023-09-22T06:44:36.174817Z","shell.execute_reply":"2023-09-22T06:44:36.187009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nfor t in range(epochs):\n    print(f'===EPOCH===  {t}')\n    trainval_loop(train_loader,val_loader, simple_net, criterion, optimizer)      # running train_val loop by 10 times","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:44:36.189537Z","iopub.execute_input":"2023-09-22T06:44:36.190136Z","iopub.status.idle":"2023-09-22T06:49:19.917651Z","shell.execute_reply.started":"2023-09-22T06:44:36.190104Z","shell.execute_reply":"2023-09-22T06:49:19.916660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_test=0\nloss=0\ncorrect_test=0\ntest_loss =0\nwith torch.no_grad():\n        for batch, (X, y) in enumerate(test_loader):\n            X = X.to(device)\n            y = y.to(device)\n            # Compute prediction and loss\n#             outputs = model(inputs)\n            pred = simple(X)\n            loss = criterion(pred, y)\n            test_loss += loss.item()\n            ## Accuracy calculation\n            \n            \n            _, predicted = torch.max(pred.data, 1)\n            total_test += y.size(0)\n            correct_test += (predicted == y).sum().item()\n            \n            if batch % 100 == 0:\n                current = batch * len(X)\n        test_accuracy = 100 * correct_test / total_test\n        print(f\" Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:49:19.919188Z","iopub.execute_input":"2023-09-22T06:49:19.920339Z","iopub.status.idle":"2023-09-22T06:49:22.308245Z","shell.execute_reply.started":"2023-09-22T06:49:19.920302Z","shell.execute_reply":"2023-09-22T06:49:22.307095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the losses\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, epochs+1), training_loss, label='Training Loss')\nplt.plot(range(1, epochs+1), validation_loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')                  \nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:49:22.309944Z","iopub.execute_input":"2023-09-22T06:49:22.310352Z","iopub.status.idle":"2023-09-22T06:49:22.620905Z","shell.execute_reply.started":"2023-09-22T06:49:22.310316Z","shell.execute_reply":"2023-09-22T06:49:22.619965Z"},"trusted":true},"execution_count":null,"outputs":[]}]}